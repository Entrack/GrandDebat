{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to allow loading large files\n",
    "import sys\n",
    "import csv\n",
    "def find_and_set_sys_maxsize():\n",
    "    maxInt = sys.maxsize\n",
    "    decrement = True\n",
    "    while decrement:\n",
    "        decrement = False\n",
    "        try:\n",
    "            csv.field_size_limit(maxInt)\n",
    "        except OverflowError:\n",
    "            maxInt = int(maxInt/10)\n",
    "            decrement = True\n",
    "find_and_set_sys_maxsize()\n",
    "\n",
    "import warnings\n",
    "def fxn():\n",
    "    warnings.warn(\"deprecated\", DeprecationWarning)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    fxn()\n",
    "\n",
    "    \n",
    "    \n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import gensim\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "# from nltk.tokenize import word_tokenize\n",
    "\n",
    "import pickle\n",
    "\n",
    "import math\n",
    "\n",
    "import datetime\n",
    "def timestamp(): return datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "granddebat_folder = '../GrandDébat/granddebat.fr/'\n",
    "democrat_path = os.path.join(granddebat_folder, 'DEMOCRATIE_ET_CITOYENNETE.csv')\n",
    "events_path = os.path.join(granddebat_folder, 'EVENTS.csv')\n",
    "fiscalit_path = os.path.join(granddebat_folder, 'LA_FISCALITE_ET_LES_DEPENSES_PUBLIQUES.csv')\n",
    "ecolog_path = os.path.join(granddebat_folder, 'LA_TRANSITION_ECOLOGIQUE.csv')\n",
    "organisat_path = os.path.join(granddebat_folder, 'ORGANISATION_DE_LETAT_ET_DES_SERVICES_PUBLICS.csv')\n",
    "\n",
    "french_encoding = \"utf-8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = democrat_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_raw = pd.read_csv(file_path, engine='python', encoding=french_encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some statistics\n",
    "* 350k rows overall\n",
    "* 0.5 not NaNs\n",
    "* 10 * 5 questions\n",
    "* 10e6 answers\n",
    "* 7k zipcodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare text dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's leave only text data and normalize the columns names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>Ew</th>\n",
       "      <th>Ex</th>\n",
       "      <th>Ey</th>\n",
       "      <th>Ez</th>\n",
       "      <th>E0</th>\n",
       "      <th>E1</th>\n",
       "      <th>E2</th>\n",
       "      <th>...</th>\n",
       "      <th>M1</th>\n",
       "      <th>M2</th>\n",
       "      <th>M3</th>\n",
       "      <th>M4</th>\n",
       "      <th>M5</th>\n",
       "      <th>Qx</th>\n",
       "      <th>Qy</th>\n",
       "      <th>Qz</th>\n",
       "      <th>Q0</th>\n",
       "      <th>Q1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Le citoyen</td>\n",
       "      <td>Non</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Afin d’éviter de creuser les inégalités ne plu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Un instrument de démocratie locale à modernise...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nous proposons le retour à la limitation de vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voir l'intégralité de la proposition dans la d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POUR UN NOUVEAU CONTRAT CITOYEN               ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>député, maire, moi même</td>\n",
       "      <td>Non</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Budget participatif, possibilité d'interpeller...</td>\n",
       "      <td>Une bonne chose</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Oui</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  A3   A4   A5  \\\n",
       "0                                         Le citoyen  Non  NaN   \n",
       "1  Un instrument de démocratie locale à modernise...  NaN  NaN   \n",
       "2                                                NaN  NaN  NaN   \n",
       "3  Voir l'intégralité de la proposition dans la d...  NaN  NaN   \n",
       "4                            député, maire, moi même  Non  NaN   \n",
       "\n",
       "                                                  Ew               Ex   Ey  \\\n",
       "0                                                NaN              NaN  NaN   \n",
       "1                                                NaN              NaN  NaN   \n",
       "2                                                NaN              NaN  NaN   \n",
       "3                                                NaN              NaN  NaN   \n",
       "4  Budget participatif, possibilité d'interpeller...  Une bonne chose  NaN   \n",
       "\n",
       "    Ez   E0   E1   E2                        ...                           M1  \\\n",
       "0  NaN  NaN  NaN  NaN                        ...                          NaN   \n",
       "1  NaN  NaN  NaN  NaN                        ...                          NaN   \n",
       "2  NaN  NaN  NaN  NaN                        ...                          NaN   \n",
       "3  NaN  NaN  NaN  NaN                        ...                          NaN   \n",
       "4  NaN  Oui  NaN  NaN                        ...                          NaN   \n",
       "\n",
       "    M2   M3   M4   M5   Qx   Qy   Qz   Q0  \\\n",
       "0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "1  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "2  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "3  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "4  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "\n",
       "                                                  Q1  \n",
       "0  Afin d’éviter de creuser les inégalités ne plu...  \n",
       "1                                                NaN  \n",
       "2  Nous proposons le retour à la limitation de vi...  \n",
       "3  POUR UN NOUVEAU CONTRAT CITOYEN               ...  \n",
       "4                                                NaN  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_reverse_index = 37\n",
    "db_questions = db_raw.loc[:, db_raw.columns[-questions_reverse_index:]]\n",
    "\n",
    "# (QA4893whateverA3, QA4893whateverA4) -> (A3, A4)\n",
    "question_list = db_raw.columns[-questions_reverse_index:]\n",
    "question_list = [el.split()[0][-2:] for el in question_list]\n",
    "db_questions.columns = question_list\n",
    "\n",
    "db_questions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for Doc2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "doc2vec wants a list of documents  \n",
    "every document is contained in a TaggedDocument(words=\"Le citoyen\", tags=[\"0 A3\"]) (par example)  \n",
    "I form the tags in the \"rowIndex columnName\" format in case we need to match documents with specific answers  \n",
    "(actually I haven't used this feature fully)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_indices = list(db_questions[db_questions.notna()].stack().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_data = [db_questions.loc[idx] for idx in question_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_tuple_to_str(index_tuple):\n",
    "    return str(index_tuple[0]) + ' ' + str(index_tuple[1])\n",
    "def str_to_index_tuple(tuple_string):\n",
    "    return (int(tuple_string.split()[0]), tuple_string.split()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_data = [TaggedDocument(words=gensim.utils.simple_preprocess(question), tags=[index_tuple_to_str(question_indices[idx])]) \n",
    "               for idx, question in enumerate(question_data)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 100\n",
    "vec_size = 16\n",
    "alpha = 0.025\n",
    "min_alpha = 0.00025\n",
    "\n",
    "model = Doc2Vec(size = vec_size,\n",
    "                alpha = alpha, \n",
    "                min_alpha = min_alpha,\n",
    "                min_count = 1,\n",
    "                dm = 1,\n",
    "                workers=8\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(tagged_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(max_epochs):\n",
    "    print('iteration {0}'.format(epoch))\n",
    "    model.train(tagged_data,\n",
    "                total_examples = model.corpus_count,\n",
    "                epochs = model.iter)\n",
    "    model.alpha -= 0.0002\n",
    "    model.min_alpha = model.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"questions_\" + timestamp() + \".model\")\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes just **infinite** amount of time to train (it runs on one thread so the cluster won't help)  \n",
    "I guess we can pass not every answer as a document, or maybe accumulate them by regions in big texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Or load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open(\"questions.model\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we have the trained doc2vec model that can convert answers to vectors  \n",
    "In order to save the vector components (there are 16 components) we can form the matrix that has not A3, A4... columns in it, but А3_0, А3_1, ... А3_15, А4_0, А4_1, ... \n",
    "So it will be the place for storing all the vectors  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_column_name_with_component(name, component):\n",
    "    return name + \"_\" + str(component)\n",
    "\n",
    "db_question_vectors = pd.DataFrame(index=db_questions.index)\n",
    "for question in db_questions.columns:\n",
    "    for idx in range(vec_size):\n",
    "        db_question_vectors[form_column_name_with_component(question, idx)] = pd.Series(dtype='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A3\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "A4\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "A5\n",
      "10000\n",
      "20000\n",
      "50000\n",
      "60000\n",
      "Ew\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "Ex\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "Ey\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "Ez\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "60000\n",
      "E0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "E1\n",
      "20000\n",
      "60000\n",
      "E2\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "E3\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "50000\n",
      "60000\n",
      "E4\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "50000\n",
      "60000\n",
      "E5\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "50000\n",
      "60000\n",
      "Iw\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "50000\n",
      "60000\n",
      "Ix\n",
      "10000\n",
      "20000\n",
      "60000\n",
      "Iy\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "60000\n",
      "Iz\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "60000\n",
      "I0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "I1\n",
      "10000\n",
      "20000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "I3\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "60000\n",
      "I4\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "60000\n",
      "I5\n",
      "10000\n",
      "20000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "Mw\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "Mx\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "My\n",
      "20000\n",
      "60000\n",
      "Mz\n",
      "10000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "M0\n",
      "10000\n",
      "30000\n",
      "40000\n",
      "60000\n",
      "M1\n",
      "10000\n",
      "30000\n",
      "40000\n",
      "60000\n",
      "M2\n",
      "10000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "M3\n",
      "10000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "M4\n",
      "10000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "M5\n",
      "40000\n",
      "60000\n",
      "Qx\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "60000\n",
      "Qy\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "60000\n",
      "Qz\n",
      "10000\n",
      "20000\n",
      "40000\n",
      "60000\n",
      "Q0\n",
      "10000\n",
      "20000\n",
      "40000\n",
      "60000\n",
      "Q1\n",
      "0\n",
      "10000\n",
      "20000\n",
      "50000\n",
      "60000\n"
     ]
    }
   ],
   "source": [
    "for question in db_questions.columns:\n",
    "    print(question)\n",
    "    for el in db_questions[db_questions[question].isna() == False][question].iteritems():\n",
    "        if index % 10000 == 0:\n",
    "            print(index)\n",
    "        index = el[0]\n",
    "        data = el[1]\n",
    "        vectorized_question = model.infer_vector(data)\n",
    "        for component_index, component_value in enumerate(vectorized_question):\n",
    "            db_question_vectors.loc[index, form_column_name_with_component(question, component_index)] = component_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_question_vectors.to_csv('db_question_vectors_' +  timestamp() + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_question_vectors = pd.read_csv('db_question_vectors.csv', engine='python', encoding=french_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = db_question_vectors\n",
    "y = db_raw['authorZipCode'].apply(lambda x: int(str(x)[0:2]))\n",
    "print(y.nunique())\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:45:29] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 94 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[20:45:29] /workspace/src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 106 extra nodes, 0 pruned nodes, max_depth=6\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "param = {}\n",
    "param['nthread'] = 8\n",
    "dtrain = xgb.DMatrix(X_train.iloc[:, :], label=y_train.iloc[:], missing=math.nan)\n",
    "bst = xgb.train(param, dtrain, num_boost_round = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.12%\n"
     ]
    }
   ],
   "source": [
    "xgb_X_test = xgb.DMatrix(X_test)\n",
    "xgb_y_test = xgb.DMatrix(y_test)\n",
    "\n",
    "y_pred = bst.predict(xgb_X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(model, open(\"xboost_\" + timestamp() + \".dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(\"xboost_.dat\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "So as we can see the XGboost model performed bad on Doc2vec data  \n",
    "I think the problem is in the fact that doc2vec was not fully trained  \n",
    "And we should anyway doubt training doc2vec in this way  \n",
    "We can either aggregate answers by region or by a person  \n",
    "Or we can use pre trained word2vec models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
